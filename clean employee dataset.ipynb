{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031a98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f59abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1aca425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-8-10 Python-3.8.10 torch-1.13.0.dev20220701+cu116 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5x6 summary: 574 layers, 140730220 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "people_detect_model = torch.hub.load('ultralytics/yolov5','custom', 'yolov5x6') #'ultralytics/yolov5', 'custom', 'yolov5s-cls.pt'\n",
    "people_detect_model.classes = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87fd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "for i in range(12):\n",
    "    Path(f'cleaned_employee_dataset_new/{i}').mkdir(parents=True, exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725e4f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2324\n",
      "1 288\n",
      "2 1222\n",
      "3 3156\n",
      "4 447\n",
      "5 2270\n",
      "6 1373\n",
      "7 190\n",
      "8 148\n",
      "9 0\n",
      "10 1831\n",
      "11 1779\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    files = list(Path(f'employee_dataset_new/{i}').glob('*.png'))\n",
    "    print(i,len(files))\n",
    "    for file in files:\n",
    "        img = cv2.imread(str(file.resolve()), cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = people_detect_model(img)\n",
    "        if results.xyxy[0].shape == torch.Size([1, 6]):\n",
    "            shutil.copy(str(file.resolve()), str(file.resolve()).replace('employee_dataset','cleaned_employee_dataset')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1acd331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1674\n",
      "1 67\n",
      "2 482\n",
      "3 1056\n",
      "4 133\n",
      "5 983\n",
      "6 498\n",
      "7 0\n",
      "8 109\n",
      "9 0\n",
      "10 867\n",
      "11 1215\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    files = list(Path(f'cleaned_employee_dataset_new/{i}').glob('*.png'))\n",
    "    print(i,len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c7b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir('cleaned_employee_dataset_new/9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9af999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1 1674\n",
      "1 1606 1673\n",
      "2 1191 1673\n",
      "3 617 1673\n",
      "4 1540 1673\n",
      "5 690 1673\n",
      "6 1175 1673\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    if i==9:\n",
    "        continue\n",
    "    files = list(Path(f'cleaned_employee_dataset_new/{i}').glob('*.png'))\n",
    "    need=1673-len(files)\n",
    "    while len(files)<1673:\n",
    "        files=files+files\n",
    "        \n",
    "    for c in range(need):\n",
    "        src_path=str(files[c])\n",
    "        dst_path=f'{files[c].parents[0]}/cpy_{c}.png'\n",
    "#         print(src_path,dst_path)\n",
    "#         break\n",
    "        shutil.copy(src_path,dst_path)\n",
    "        \n",
    "    files = list(Path(f'cleaned_employee_dataset_new/{i}').glob('*.png'))\n",
    "    print(i,need,len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1177beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 36, 3)\n",
      "(274, 109, 3)\n",
      "(95, 36, 3)\n",
      "(309, 137, 3)\n",
      "(336, 88, 3)\n",
      "(330, 116, 3)\n",
      "(193, 93, 3)\n",
      "(316, 102, 3)\n",
      "(96, 44, 3)\n",
      "(74, 19, 3)\n",
      "(272, 75, 3)\n",
      "(74, 21, 3)\n",
      "(45, 16, 3)\n",
      "(102, 43, 3)\n",
      "(158, 65, 3)\n",
      "(361, 154, 3)\n",
      "(77, 21, 3)\n",
      "(78, 26, 3)\n",
      "(310, 199, 3)\n",
      "(75, 27, 3)\n",
      "(329, 92, 3)\n",
      "(75, 29, 3)\n",
      "(362, 141, 3)\n",
      "(87, 28, 3)\n",
      "(260, 97, 3)\n",
      "(327, 113, 3)\n",
      "(79, 28, 3)\n",
      "(86, 28, 3)\n",
      "(71, 31, 3)\n",
      "(88, 33, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "for i in range(12):\n",
    "    if i==9:\n",
    "        continue\n",
    "    files = list(Path(f'cleaned_employee_dataset_new/{i}').glob('*.png'))\n",
    "    cnt=0\n",
    "    for file in files:\n",
    "        cnt+=1\n",
    "        if cnt>30:\n",
    "            break\n",
    "        img = cv2.imread(str(file), cv2.IMREAD_UNCHANGED)\n",
    "        print(img.shape)\n",
    "    break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb84543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00181914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f27f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15ec7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
